import aiohttp, asyncio, pandas as pd
from datetime import datetime, timedelta, timezone
import pytz
import ssl

BASE_UPBIT = "https://api.upbit.com/v1"
BASE_BINANCE = "https://api.binance.com/api/v3"


# ------------------------------------------------------------
# Upbit KRW-USDT ìº”ë“¤ ìˆ˜ì§‘
# ------------------------------------------------------------
async def fetch_usdt_candles(interval="minutes/15", mode="agent", lookback=200,
                             tz="Asia/Seoul", save_csv=False, csv_name=None):
    """
    Upbit KRW-USDT ìº”ë“¤ ìˆ˜ì§‘ (15ë¶„ë´‰ / ì¼ë´‰)
    mode:
      - 'agent': ìµœê·¼ nê°œë§Œ
      - 'full': ê°€ëŠ¥í•œ ê³¼ê±°ê¹Œì§€
    """
    utc = timezone.utc
    kst = pytz.timezone(tz)
    all_candles = []

    async with aiohttp.ClientSession() as sess:
        if mode == "agent":
            # âœ… ìµœê·¼ lookbackê°œë§Œ ìˆ˜ì§‘
            url = f"{BASE_UPBIT}/candles/{interval}"
            params = {"market": "KRW-USDT", "count": lookback}
            async with sess.get(url, params=params) as resp:
                data = await resp.json()

            if isinstance(data, dict) and "error" in data:
                print("âš ï¸ Upbit API error:", data["error"].get("message"))
                return pd.DataFrame()

            for d in sorted(data, key=lambda x: x["candle_date_time_utc"]):
                ts = datetime.fromisoformat(d["candle_date_time_utc"]).replace(tzinfo=utc)
                all_candles.append({
                    "timestamp_utc": ts,
                    "timestamp_kst": ts.astimezone(kst),
                    "open": float(d["opening_price"]),
                    "high": float(d["high_price"]),
                    "low": float(d["low_price"]),
                    "close": float(d["trade_price"]),
                    "volume": float(d["candle_acc_trade_volume"]),
                })

        elif mode == "full":
            # âœ… ê°€ëŠ¥í•œ í•œ ì˜¤ë˜ëœ ë°ì´í„°ê¹Œì§€ ì „ë¶€ ìˆ˜ì§‘
            print(f"ğŸš€ Start full data collection: KRW-USDT ({interval})")

            end = datetime.now(pytz.timezone("Asia/Seoul"))
            last_oldest = None
            request_count = 0

            while True:
                url = f"{BASE_UPBIT}/candles/{interval}"
                params = {
                    "market": "KRW-USDT",
                    "count": 200,
                    "to": end.strftime("%Y-%m-%d %H:%M:%S")
                }

                async with sess.get(url, params=params) as resp:
                    data = await resp.json()

                if isinstance(data, dict) and "error" in data:
                    print("âš ï¸ Upbit API error:", data["error"].get("message"))
                    break
                if not data:
                    print("âœ… No more data, stopping.")
                    break

                # âœ… ì •ë ¬ ë° ëˆ„ì 
                for d in sorted(data, key=lambda x: x["candle_date_time_utc"]):
                    ts = datetime.fromisoformat(d["candle_date_time_utc"]).replace(tzinfo=utc)
                    all_candles.append({
                        "timestamp_utc": ts,
                        "timestamp_kst": ts.astimezone(kst),
                        "open": float(d["opening_price"]),
                        "high": float(d["high_price"]),
                        "low": float(d["low_price"]),
                        "close": float(d["trade_price"]),
                        "volume": float(d["candle_acc_trade_volume"]),
                    })

                if "minutes" in interval:
                    # ì˜ˆ: "minutes/15" â†’ 15
                    step_min = int(interval.split("/")[1])
                    step = timedelta(minutes=step_min)
                else:
                    # "days"
                    step = timedelta(days=1)

                oldest = datetime.fromisoformat(data[-1]["candle_date_time_kst"])

                # âœ… ë™ì¼ timestamp ë°˜ë³µ ë°©ì§€
                if last_oldest and abs((last_oldest - oldest).total_seconds()) < 1:
                    print("âš ï¸ ë™ì¼ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜ë³µ ê°ì§€ â†’ ë£¨í”„ ì¢…ë£Œ")
                    break
                last_oldest = oldest

                end = oldest - step
                request_count += 1

                if request_count % 10 == 0:
                    print(f"ğŸ“ˆ {request_count}íšŒ ìš”ì²­ ì™„ë£Œ, ì´ {len(all_candles)}ë´‰, oldest={oldest}")
                await asyncio.sleep(0.2)

    if not all_candles:
        print("âš ï¸ No data fetched.")
        return pd.DataFrame()

    # âœ… ì •ë¦¬
    df = pd.DataFrame(all_candles).drop_duplicates(subset="timestamp_utc")
    df = df.sort_values("timestamp_utc").reset_index(drop=True)

    if save_csv:
        safe_interval = interval.replace("/", "_")
        today = datetime.now().strftime("%Y%m%d")
        name = csv_name or f"USDT_15m_{today}.csv"
        df.to_csv(name, index=False)
        print(f"ğŸ’¾ CSV saved: {name} ({len(df)} rows)")

    return df

# ------------------------------------------------------------
# âœ… NBP í™˜ìœ¨ ìˆ˜ì§‘ (ê¸°ê°„ë³„, ì²­í¬ ë¶„í•  + ìë™ ë³´ì •)
# ------------------------------------------------------------
async def fetch_usdkrw_timeseries(start_date, end_date):
    """
    NBP API ê¸°ê°„ ìš”ì²­ ì œí•œ(367ì¼)ì„ í”¼í•˜ê¸° ìœ„í•´ ê¸°ê°„ì„ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ  ìš”ì²­.
    ê° ì²­í¬ ì‹¤íŒ¨ ì‹œ 180â†’90â†’30â†’7â†’1ì¼ ë‹¨ìœ„ë¡œ ì¶•ì†Œ ì¬ì‹œë„.
    """
    ssl_ctx = ssl.create_default_context()
    ssl_ctx.check_hostname = False
    ssl_ctx.verify_mode = ssl.CERT_NONE

    async def fetch_chunk(sess, s, e):
        url_usd = f"https://api.nbp.pl/api/exchangerates/rates/A/USD/{s}/{e}/?format=json"
        url_krw = f"https://api.nbp.pl/api/exchangerates/rates/A/KRW/{s}/{e}/?format=json"
        async with sess.get(url_usd) as r_usd, sess.get(url_krw) as r_krw:
            if r_usd.status != 200 or r_krw.status != 200:
                # âœ… ì£¼ë§ êµ¬ê°„ì´ë©´ ì§ì „ í‰ì¼ í™˜ìœ¨ë¡œ ì±„ìš°ê¸°
                print(f"âš ï¸ NBP êµ¬ê°„ ì‹¤íŒ¨ {s}~{e}: USD {r_usd.status}, KRW {r_krw.status}")
                return "WEEKEND_FILL"
            usd_data = await r_usd.json(content_type=None)
            krw_data = await r_krw.json(content_type=None)
        if "rates" not in usd_data or "rates" not in krw_data:
            return None
        usd_df = pd.DataFrame(usd_data["rates"])
        krw_df = pd.DataFrame(krw_data["rates"])
        if usd_df.empty or krw_df.empty:
            return None
        df = pd.merge(
            usd_df.rename(columns={"effectiveDate": "date", "mid": "usd_pln"}),
            krw_df.rename(columns={"effectiveDate": "date", "mid": "krw_pln"}),
            on="date", how="inner"
        )
        if df.empty:
            return None
        df["date"] = pd.to_datetime(df["date"])
        df["usdkrw"] = df["usd_pln"] / df["krw_pln"]
        if df["usdkrw"].median() > 5000:
            df["usdkrw"] /= 100.0
        return df[["date", "usdkrw"]]

    frames = []
    chunk_sizes = [360, 180, 90, 30, 7, 1]
    cur = pd.to_datetime(start_date).date()
    end_dt = pd.to_datetime(end_date).date()

    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=ssl_ctx)) as sess:
        last_valid_df = None
        while cur <= end_dt:
            got = None
            for days in chunk_sizes:
                chunk_end = min(end_dt, cur + timedelta(days=days))
                s = cur.strftime("%Y-%m-%d")
                e = chunk_end.strftime("%Y-%m-%d")
                got = await fetch_chunk(sess, s, e)
                if got is not None:
                    break
            if isinstance(got, str) and got == "WEEKEND_FILL":
                # âœ… ì£¼ë§ êµ¬ê°„ì´ë©´ ì§ì „ í‰ì¼ í™˜ìœ¨ë¡œ ì±„ì›€
                weekend_dates = pd.date_range(start=cur, end=chunk_end)
                # ì§ì „ í‰ì¼ í™˜ìœ¨ ì°¾ê¸°
                if last_valid_df is not None and not last_valid_df.empty:
                    last_rate = last_valid_df["usdkrw"].iloc[-1]
                else:
                    last_rate = 1300.0  # ê¸°ë³¸ê°’
                fill_df = pd.DataFrame({"date": weekend_dates, "usdkrw": [last_rate] * len(weekend_dates)})
                frames.append(fill_df)
                print(f"âœ… ì£¼ë§ êµ¬ê°„ {cur}~{chunk_end}: ì§ì „ í‰ì¼ í™˜ìœ¨({last_rate})ë¡œ ì±„ì›€")
                cur = chunk_end + timedelta(days=1)
                continue
            if got is None:
                print(f"âš ï¸ {cur}~ êµ¬ê°„ ì™„ì „ ì‹¤íŒ¨, í•˜ë£¨ ê±´ë„ˆëœ€")
                cur += timedelta(days=1)
                continue
            frames.append(got)
            last_valid_df = got
            cur = got["date"].max().date() + timedelta(days=1)
            await asyncio.sleep(0.05)

    if not frames:
        print("âš ï¸ NBP í™˜ìœ¨ ìˆ˜ì§‘ ì‹¤íŒ¨")
        return pd.DataFrame(columns=["date", "usdkrw"])

    full = pd.concat(frames, ignore_index=True)
    full = full.drop_duplicates(subset="date").sort_values("date").reset_index(drop=True)
    # âœ… ê²°ì¸¡ê°’ ë³´ì •: ì•ë’¤ ê°’ìœ¼ë¡œ ì±„ì›€
    full["usdkrw"] = full["usdkrw"].ffill().bfill()
    return full[["date", "usdkrw"]]


# ------------------------------------------------------------
# âœ… BTC ê¸°ì¤€ ê¹€ì¹˜í”„ë¦¬ë¯¸ì—„ (USDT ê¸°ì¤€ ì „ì²´ ë™ê¸°í™”)
# ------------------------------------------------------------
async def fetch_kimchi_daily(mode="agent", lookback=200, save_csv=False):
    utc = timezone.utc
    kst = pytz.timezone("Asia/Seoul")

    async with aiohttp.ClientSession() as sess:

        # â‘  Upbit KRW/USDT (ê¸°ì¤€ ë°ì´í„°)
        all_usdt = []
        if mode == "agent":
            url = f"{BASE_UPBIT}/candles/days"
            params = {"market": "KRW-USDT", "count": lookback}
            async with sess.get(url, params=params) as resp:
                data = await resp.json()
            data = sorted(data, key=lambda x: x["candle_date_time_utc"])
            for d in data:
                ts = datetime.fromisoformat(d["candle_date_time_utc"]).replace(tzinfo=utc)
                all_usdt.append({
                    "timestamp_utc": ts,
                    "timestamp_kst": ts.astimezone(kst),
                    "close": float(d["trade_price"])
                })
        else:
            print(f"ğŸš€ Start full data collection: Upbit KRW/USDT, K-premium (days)")
            end = datetime.now(kst)
            last_oldest = None
            while True:
                url = f"{BASE_UPBIT}/candles/days"
                params = {"market": "KRW-USDT", "count": 200, "to": end.strftime("%Y-%m-%d %H:%M:%S")}
                async with sess.get(url, params=params) as resp:
                    data = await resp.json()
                if not data:
                    print("âœ… No more data, stopping.")
                    break
                data = sorted(data, key=lambda x: x["candle_date_time_utc"])
                for d in data:
                    ts = datetime.fromisoformat(d["candle_date_time_utc"]).replace(tzinfo=utc)
                    all_usdt.append({
                        "timestamp_utc": ts,
                        "timestamp_kst": ts.astimezone(kst),
                        "close": float(d["trade_price"])
                    })
                oldest = datetime.fromisoformat(data[-1]["candle_date_time_kst"])
                if last_oldest and abs((last_oldest - oldest).total_seconds()) < 1:
                    break
                last_oldest = oldest
                end = oldest - timedelta(days=200)
                print(f"ğŸ“ˆ ì´ {len(all_usdt)}ë´‰, oldest={oldest.date()}")
                await asyncio.sleep(0.25)

        if not all_usdt:
            print("âš ï¸ Upbit KRW/USDT ë°ì´í„° ì—†ìŒ.")
            return pd.DataFrame()

        upbit_usdt = pd.DataFrame(all_usdt)
        upbit_usdt["date"] = upbit_usdt["timestamp_utc"].dt.date
        usdt_min, usdt_max = upbit_usdt["date"].min(), upbit_usdt["date"].max()

        # â‘¡ Upbit BTC/KRW
        all_btc = []
        end = datetime.now(kst)
        last_oldest = None
        while True:
            url = f"{BASE_UPBIT}/candles/days"
            params = {"market": "KRW-BTC", "count": 200, "to": end.strftime("%Y-%m-%d %H:%M:%S")}
            async with sess.get(url, params=params) as resp:
                data = await resp.json()
            if not data:
                break
            data = sorted(data, key=lambda x: x["candle_date_time_utc"])
            for d in data:
                ts = datetime.fromisoformat(d["candle_date_time_utc"]).replace(tzinfo=utc)
                all_btc.append({
                    "timestamp_utc": ts,
                    "timestamp_kst": ts.astimezone(kst),
                    "close": float(d["trade_price"])
                })
            oldest = datetime.fromisoformat(data[-1]["candle_date_time_kst"])
            if last_oldest and abs((last_oldest - oldest).total_seconds()) < 1:
                break
            if oldest.date() < usdt_min:
                break
            last_oldest = oldest
            end = oldest - timedelta(days=200)
            await asyncio.sleep(0.25)

        upbit_btc = pd.DataFrame(all_btc)
        upbit_btc["date"] = upbit_btc["timestamp_utc"].dt.date
        upbit_btc = upbit_btc[(upbit_btc["date"] >= usdt_min) & (upbit_btc["date"] <= usdt_max)]

        # â‘¢ Binance BTC/USDT
        url_binance = f"{BASE_BINANCE}/klines"
        params_bin = {"symbol": "BTCUSDT", "interval": "1d", "limit": (usdt_max - usdt_min).days + 1}
        async with sess.get(url_binance, params=params_bin) as resp:
            data_bin = await resp.json()
        binance_btc = pd.DataFrame([
            {"timestamp_utc": datetime.utcfromtimestamp(d[0] / 1000).replace(tzinfo=utc), "close": float(d[4])}
            for d in data_bin
        ])
        binance_btc["date"] = binance_btc["timestamp_utc"].dt.date
        binance_btc = binance_btc[(binance_btc["date"] >= usdt_min) & (binance_btc["date"] <= usdt_max)]

        # â‘£ NBP í™˜ìœ¨
        nbp_fx = await fetch_usdkrw_timeseries(start_date=usdt_min, end_date=usdt_max)

    # âœ… íƒ€ì… í†µì¼
    for df in [upbit_btc, binance_btc, upbit_usdt, nbp_fx]:
        df["date"] = pd.to_datetime(df["date"]).dt.date

    # âœ… ë³‘í•© ë° ê³„ì‚°
    merged = (
        upbit_btc
        .merge(binance_btc.add_prefix("binance_"), left_on="date", right_on="binance_date", how="inner")
        .merge(upbit_usdt.add_prefix("usdt_"), left_on="date", right_on="usdt_date", how="inner")
        .merge(nbp_fx, on="date", how="left")
        .sort_values("date").reset_index(drop=True)
    )
    merged["usdkrw"] = merged["usdkrw"].ffill().bfill()
    merged.rename(columns={
        "close": "upbit_btc_krw",
        "binance_close": "binance_btc_usdt",
        "usdt_close": "upbit_usdt_krw",
    }, inplace=True)
    merged["kimchi_premium(%)"] = (
        (merged["upbit_btc_krw"] - merged["binance_btc_usdt"] * merged["usdkrw"])
        / (merged["binance_btc_usdt"] * merged["usdkrw"])
    ) * 100

    # âœ… ë¶ˆí•„ìš”í•œ ì¤‘ê°„ ì»¬ëŸ¼ ì •ë¦¬
    merged = merged.drop(columns=[
        "binance_timestamp_utc", "binance_date",
        "usdt_timestamp_utc", "usdt_timestamp_kst", "usdt_date", "date"
    ], errors="ignore")

    if save_csv:
        today = datetime.now().strftime("%Y%m%d")
        name = f"USDT_kimchi_days_{today}.csv"
        merged.to_csv(name, index=False)
        print(f"ğŸ’¾ Saved: {name} ({len(merged)} rows)")

    return merged


# ------------------------------------------------------------
# ì‹¤í–‰ ì˜ˆì‹œ
# ------------------------------------------------------------
if __name__ == "__main__":
    async def main():
        # âœ… [1] KRW-USDT 15ë¶„ë´‰ (Agent)
        df15_agent = await fetch_usdt_candles(interval="minutes/15", mode="agent", lookback=15)
        print(f"ğŸ“Š 15ë¶„ë´‰ (ìµœê·¼) ìˆ˜ì§‘ ì™„ë£Œ: {len(df15_agent)} rows")

        # âœ… [2] KRW-USDT 15ë¶„ë´‰ (Full + CSV)
        df15_full = await fetch_usdt_candles(interval="minutes/15", mode="full", save_csv=True)
        print(f"ğŸ’¾ 15ë¶„ë´‰ ì „ì²´ ì €ì¥ ì™„ë£Œ: {len(df15_full)} rows")

        # âœ… [3] KRW-USDT 1ì¼ë´‰ + ê¹€í”„ (Agent)
        df_kimchi_agent = await fetch_kimchi_daily(mode="agent", lookback=30)
        print(f"ğŸ“ˆ ê¹€í”„(Agent) ê³„ì‚° ì™„ë£Œ: {len(df_kimchi_agent)} rows")

        # âœ… [4] KRW-USDT 1ì¼ë´‰ + ê¹€í”„ (Full + CSV)
        df_kimchi_full = await fetch_kimchi_daily(mode="full", save_csv=True)
        print(f"ğŸ’¾ ê¹€í”„(Full) CSV ì €ì¥ ì™„ë£Œ: {len(df_kimchi_full)} rows")

    asyncio.run(main())
